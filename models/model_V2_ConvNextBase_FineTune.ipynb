{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba5a1f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\OneDrive\\Escritorio\\Proyecto_IA_SS\\venv\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import sklearn\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f60ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "def read_and_decode(filename):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return img\n",
    "\n",
    "def decode_csv(csv_row):\n",
    "    record_defaults = [\"filepaths\", \"labels\"]\n",
    "    filename, label_string = tf.io.decode_csv(csv_row, record_defaults)\n",
    "    img = read_and_decode(filename)\n",
    "    return img, label_string\n",
    "\n",
    "dataset = (tf.data.TextLineDataset(\n",
    "    \"new_train.csv\").\n",
    "    map(decode_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6a62ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'0', shape=(), dtype=string) tf.Tensor([0.26415765 0.26415765 0.26415765], shape=(3,), dtype=float32)\n",
      "tf.Tensor(b'1', shape=(), dtype=string) tf.Tensor([0.09402619 0.09402619 0.09402619], shape=(3,), dtype=float32)\n",
      "tf.Tensor(b'1', shape=(), dtype=string) tf.Tensor([0.12388248 0.12388248 0.12388248], shape=(3,), dtype=float32)\n",
      "tf.Tensor(b'1', shape=(), dtype=string) tf.Tensor([0.0780125 0.0780125 0.0780125], shape=(3,), dtype=float32)\n",
      "tf.Tensor(b'1', shape=(), dtype=string) tf.Tensor([0.09578612 0.09578612 0.09578612], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for img, label in dataset.take(5):\n",
    "    avg = tf.math.reduce_mean(img, axis=[0, 1]) # average pixel in the image\n",
    "    print(label, avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0facc3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _decode_csv(csv_row):\n",
    "    record_defaults = [\"path\", \"class\"]\n",
    "    try:\n",
    "        filename, label_string = tf.io.decode_csv(csv_row, record_defaults)\n",
    "        img = read_and_decode(filename)\n",
    "        label = tf.argmax(tf.math.equal([\"0\",\"1\"], label_string))\n",
    "    except:\n",
    "        print('File corrupted')\n",
    "    return img, label\n",
    "\n",
    "\n",
    "train_dataset = (tf.data.TextLineDataset('new_train.csv').map(_decode_csv)).batch(32)\n",
    "test_dataset = (tf.data.TextLineDataset('new_test.csv').map(_decode_csv)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf02e6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<_BatchDataset element_spec=(TensorSpec(shape=(None, None, None, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n",
       " <_BatchDataset element_spec=(TensorSpec(shape=(None, None, None, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbbf09ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom metrics\n",
    "class pFBeta(tf.keras.metrics.Metric):\n",
    "    def __init__(self, beta=1, name='pF1', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.beta = beta\n",
    "        self.epsilon = 1e-10\n",
    "        self.pos = self.add_weight(name='pos', initializer='zeros')\n",
    "        self.ctp = self.add_weight(name='ctp', initializer='zeros')\n",
    "        self.cfp = self.add_weight(name='cfp', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.clip_by_value(y_pred, 0, 1)\n",
    "        pos = tf.cast(tf.reduce_sum(y_true), tf.float32)\n",
    "        ctp = tf.cast(tf.reduce_sum(y_pred[y_true == 1]), tf.float32)\n",
    "        cfp = tf.cast(tf.reduce_sum(y_pred[y_true == 0]), tf.float32)\n",
    "        self.pos.assign_add(pos)\n",
    "        self.ctp.assign_add(ctp)\n",
    "        self.cfp.assign_add(cfp)\n",
    "\n",
    "    def result(self):\n",
    "        beta2 = self.beta * self.beta\n",
    "        prec = self.ctp / (self.ctp + self.cfp + self.epsilon)\n",
    "        reca = self.ctp / (self.pos + self.epsilon)\n",
    "        return (1 + beta2) * prec * reca / (beta2 * prec + reca)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.pos.assign(0.)\n",
    "        self.ctp.assign(0.)\n",
    "        self.cfp.assign(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb7c2382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " convnext_base (Functional)  (None, 1024)              87566464  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                65600     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 87,632,129\n",
      "Trainable params: 65,665\n",
      "Non-trainable params: 87,566,464\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "base_model = tf.keras.applications.convnext.ConvNeXtBase(include_top= False,\n",
    "                                                         weights= \"imagenet\",\n",
    "                                                        input_shape= (256, 256, 3),\n",
    "                                                        pooling= 'max')\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.Dense(64, activation='sigmoid'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1, activation='softmax')])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08de85ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [pFBeta(beta=1, name='pF1'),\n",
    "                   tfa.metrics.F1Score(num_classes=1, threshold=0.50, name='F1'),\n",
    "                   tf.metrics.Precision(name='Prec'),\n",
    "                   tf.metrics.Recall(name='Reca'),\n",
    "                   tf.metrics.AUC(name='AUC'),\n",
    "                   tf.metrics.BinaryAccuracy(name='BinAcc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17f1a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.experimental.SGD(momentum=0.9),\n",
    "                loss= tf.keras.losses.BinaryCrossentropy(from_logits=False, label_smoothing=0.1), metrics= metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b42280",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a3619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, \n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_data=test_dataset,\n",
    "    callbacks=[callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
